{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Feature Engineering #2 Baseline",
      "provenance": [],
      "collapsed_sections": [
        "vzF4X-W6ZiB4",
        "jwdhQYsbPBz5",
        "Z9EbIwd6ZBKp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47009e862f264ac5b46ae009c1ee4183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acdad89e82274720ab1ed63433a287b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d6a12ed86a744ee985153e48731494c",
              "IPY_MODEL_d828d97871704b6cbb5d71d164d1de4b",
              "IPY_MODEL_045501585ff347b7a32152905f582e01"
            ]
          }
        },
        "acdad89e82274720ab1ed63433a287b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d6a12ed86a744ee985153e48731494c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7152b80401e348068a4e8a619008e746",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd6825f3728d4e7bbd3d71eb81597284"
          }
        },
        "d828d97871704b6cbb5d71d164d1de4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_83f289d1aed0412cba5642ae970bcf47",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e17f6029d9e49898eec89beea0f8994"
          }
        },
        "045501585ff347b7a32152905f582e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ca27a545b174ba2aac3d63684cc9fc9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/? [00:00&lt;00:00, 19.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17952e2d36c24ebca462867927b12c59"
          }
        },
        "7152b80401e348068a4e8a619008e746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd6825f3728d4e7bbd3d71eb81597284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83f289d1aed0412cba5642ae970bcf47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e17f6029d9e49898eec89beea0f8994": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ca27a545b174ba2aac3d63684cc9fc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17952e2d36c24ebca462867927b12c59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42531cf0d4ce4666a5571945112a6473": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">submission.zip</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100.0%</span> • <span style=\"color: #008000; text-decoration-color: #008000\">43.0/41.4 KB</span> • <span style=\"color: #800000; text-decoration-color: #800000\">317.0 kB/s</span> • <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span>\n</pre>\n",
                  "text/plain": "\u001b[1;34msubmission.zip\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100.0%\u001b[0m • \u001b[32m43.0/41.4 KB\u001b[0m • \u001b[31m317.0 kB/s\u001b[0m • \u001b[36m0:00:00\u001b[0m\n"
                },
                "metadata": {}
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_bc8500232b84467c81f5fdce275825c3",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "bc8500232b84467c81f5fdce275825c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](https://images.aicrowd.com/raw_images/challenges/banner_file/1007/6edbed5d4a9dd4d28f16.jpg)\n",
        "\n",
        "<h2><center>Starter Code for NLP Feature Engineering #2</center></h2>\n",
        "\n",
        "<!-- <h6><center>Author : Shubhamai</center></h6> -->\n",
        "\n",
        "\n",
        "\n",
        "<!-- --- -->\n",
        "\n",
        "\n",
        "\n",
        "### What we are going to Learn\n",
        "\n",
        "  - How to convert your text into numbers ?\n",
        "  - How Bag of words, TF-IDF works ?\n",
        "  - Testing and Submitting the Results to the Challenge. "
      ],
      "metadata": {
        "id": "vzF4X-W6ZiB4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwdhQYsbPBz5"
      },
      "source": [
        "## About this Challanges\n",
        "\n",
        "Now, this challange is very different form what we usually do in AIcrowd Blitz.In this challanges, the task is to generate features from a text data. Extracting features helps up to generate text embeddings will contains more useful information about the text. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0zOYXJY_mx"
      },
      "source": [
        "# Setup AIcrowd Utilities 🛠\n",
        "\n",
        "We use this to bundle the files for submission and create a submission on AIcrowd. Do not edit this block."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvMvUZ9aZBvL"
      },
      "source": [
        "%%capture\n",
        "!pip install -q -U aicrowd-cli\n",
        "%load_ext aicrowd.magic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9EbIwd6ZBKp"
      },
      "source": [
        "## How to use this notebook? 📝\n",
        "\n",
        "<p style=\"text-align: center\"><img src=\"https://gitlab.aicrowd.com/aicrowd/assets/-/raw/master/notebook/aicrowd_notebook_submission_flow.png?inline=false\" alt=\"notebook overview\" style=\"width: 650px;\"/></p>\n",
        "\n",
        "- **Update the config parameters**. You can define the common variables here\n",
        "\n",
        "Variable | Description\n",
        "--- | ---\n",
        "`AICROWD_DATASET_PATH` | Path to the file containing test data (The data will be available at `/data/` on aridhia workspace). This should be an absolute path.\n",
        "`AICROWD_OUTPUTS_PATH` | Path to write the output to.\n",
        "`AICROWD_ASSETS_DIR` | In case your notebook needs additional files (like model weights, etc.,), you can add them to a directory and specify the path to the directory here (please specify relative path). The contents of this directory will be sent to AIcrowd for evaluation.\n",
        "`AICROWD_API_KEY` | In order to submit your code to AIcrowd, you need to provide your account's API key. This key is available at https://www.aicrowd.com/participants/me\n",
        "\n",
        "- **Installing packages**. Please use the [Install packages 🗃](#Install-packages-🗃) section to install the packages\n",
        "- **Training your models**. All the code within the [Training phase ⚙️](#Training-phase-⚙️) section will be skipped during evaluation. **Please make sure to save your model weights in the assets directory and load them in the predictions phase section** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDLGIamsZI-Q"
      },
      "source": [
        "## AIcrowd Runtime Configuration 🧷\n",
        "\n",
        "Define configuration parameters. Please include any files needed for the notebook to run under `ASSETS_DIR`. We will copy the contents of this directory to your final submission file 🙂\n",
        "\n",
        "The dataset is available under `/data` on the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcY_MMl_ZLur"
      },
      "source": [
        "import os\n",
        "\n",
        "# Please use the absolute for the location of the dataset.\n",
        "# Or you can use relative path with `os.getcwd() + \"test_data/test.csv\"`\n",
        "AICROWD_DATASET_PATH = os.getenv(\"DATASET_PATH\", os.getcwd()+\"/data/data.csv\")\n",
        "AICROWD_OUTPUTS_PATH = os.getenv(\"OUTPUTS_DIR\", \"\")\n",
        "AICROWD_ASSETS_DIR = os.getenv(\"ASSETS_DIR\", \"assets\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3bHV9SL5tnX"
      },
      "source": [
        "# Install packages 🗃\n",
        "\n",
        "We are going to use many different libraries to demonstrate many idfferent techniques to convert text into numbers ( or more specifically vectors )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXBdVazs4s09",
        "outputId": "9f2eaea7-37f2-4a8d-b483-e6a7c8c0ad53"
      },
      "source": [
        "!pip install --upgrade spacy rich gensim tensorflow scikit-learn\n",
        "!python -m spacy download en_core_web_sm # Downloaing the model for english language will contains many pretrained preprocessing pipelines "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.7/dist-packages (10.16.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 41.2 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.12\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.26.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Collecting typer<0.5.0,>=0.3.0\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 693 kB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from rich) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich) (2.6.1)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from rich) (0.4.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy, scikit-learn, gensim\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed catalogue-2.0.6 gensim-4.1.2 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 scikit-learn-1.0.2 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.8.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97b5nvSbZQvk"
      },
      "source": [
        "# Define preprocessing code 💻\n",
        "\n",
        "The code that is common between the training and the prediction sections should be defined here. During evaluation, we completely skip the training section. Please make sure to add any common logic between the training and prediction sections here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjhfHq-FWozF"
      },
      "source": [
        "# Importing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Tensorflow \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "\n",
        "# Word2vec Implementation\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', exclude=['tagger', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "\n",
        "# To make things more beautiful! \n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "from rich.segment import Segment\n",
        "from rich import pretty\n",
        "pretty.install()\n",
        "\n",
        "# Seeding everything for getting same results \n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# function to display YouTube videos\n",
        "from IPython.display import YouTubeVideo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0scmOnsHfhHz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "809ae737-0896-4b96-83e0-db78951cb1cd"
      },
      "source": [
        "# Latest version of gensim\n",
        "import gensim\n",
        "gensim.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'4.1.2'</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32m'4.1.2'\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f85RERIEWt9n"
      },
      "source": [
        "# Defining the function for preprocessing test dataset which will run after submitting the notebook\n",
        "\n",
        "def tokenize_sentence(sentences, num_words=10000, maxlen=256, show=False): \n",
        "\n",
        "  # Creating the tokenizer, the num_words represents the vocabulary and assigning OOV token ( out of vocaculary ) for unknown tokenn\n",
        "  # Which can arise if we input a sentence containing a words that tokenizer don't have in his vocabulary\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "\n",
        "\n",
        "  tokenizer.fit_on_texts(sentences)\n",
        "  \n",
        "  # Getting the unique ID for each token\n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  # Convert the senteces into vector\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "  # Padding the vectors so that all vectors have the same length\n",
        "  padded_sequences = pad_sequences(sequences, padding='post', truncating='pre', maxlen=maxlen)\n",
        "\n",
        "\n",
        "  word_index = np.asarray(word_index)\n",
        "  sequences = np.asarray(sequences)\n",
        "  padded_sequences = np.asarray(padded_sequences)\n",
        "\n",
        "  if show==True:\n",
        "    console = Console()\n",
        "\n",
        "    console.log(\"Word Index. A unique ID is assigned to each token.\")\n",
        "    console.log(word_index)\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "    console.log(\"Sequences. senteces converted into vector.\")\n",
        "    console.log(np.array(sequences[0]))\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "    console.log(\"Padded Sequences. Adding,( 0 in this case ) or removing elements to make all vectors in the samples same.\")\n",
        "    console.log(np.array(padded_sequences[0]))\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "\n",
        "\n",
        "  return tokenizer, word_index, sequences, padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWdct35aZTA-"
      },
      "source": [
        "# Training phase ⚙️\n",
        "\n",
        "You can define your training code here. This sections will be skipped during evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLY4t6qn7YxG"
      },
      "source": [
        "## Downloading Dataset\n",
        "\n",
        "Must be prety familar thing by now :) In case, here we are downloading the challange dataset using AIcrowd CLI "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSsX9Rb97an9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53547d0e-89f1-4db4-a05b-4e29fa9693e7"
      },
      "source": [
        "%aicrowd login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login here: \u001b[34m\u001b[1m\u001b[4mhttps://api.aicrowd.com/auth/v8lvFNYrbzG2z76VDxvs58ogtqbzRNjoK7XEZp3tx54\u001b[0m\n",
            "\u001b[32mAPI Key valid\u001b[0m\n",
            "\u001b[32mSaved API Key successfully!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPoZQ0dBNZbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe409dbc-7778-461a-c67b-a39d6459864d"
      },
      "source": [
        "# Downloading the Dataset\n",
        "!mkdir data\n",
        "!aicrowd dataset download --challenge nlp-feature-engineering-2 -j 3 -o data\n",
        "\n",
        "# Donwloading programming language classification dataset for testing purposes\n",
        "!mkdir programming-language-data\n",
        "!aicrowd dataset download --challenge programming-language-classification -j 3 -o programming-language-data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.csv: 100% 8.37k/8.37k [00:00<00:00, 260kB/s]\n",
            "sample_submission.csv:   0% 0.00/121k [00:00<?, ?B/s]\n",
            "test.csv:   0% 0.00/1.50M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "sample_submission.csv: 100% 121k/121k [00:00<00:00, 619kB/s]\n",
            "\n",
            "test.csv: 100% 1.50M/1.50M [00:00<00:00, 2.89MB/s]\n",
            "\n",
            "\n",
            "train.csv: 100% 7.71M/7.71M [00:00<00:00, 11.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fYZjTxSYbwt"
      },
      "source": [
        "### Reading Dataset\n",
        "\n",
        "Reading the necessary files to train, validation & submit our results! \n",
        "\n",
        "We are also using [Programming Language Challange](https://www.aicrowd.com/challenges/ai-blitz-xii/problems/programming-language-classification) dataset for testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqRgB3SWYes1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "bfa327a9-e63c-4630-c986-7b0ea97fd35b"
      },
      "source": [
        "dataset = pd.read_csv(\"data/data.csv\")\n",
        "train_data = pd.read_csv(\"programming-language-data/train.csv\")\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2b0436d0-6c75-4d0e-86f6-becd651bc31a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Incels can't even get a pleb thing called sex....</td>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Seriously? I couldn't even remember the dude's...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Seeing [NAME] on Sunday and I'm so fucking stoked</td>\n",
              "      <td>[0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Your not winning their hearts, your just tortu...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This sub needs more Poison memes.</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>It is part of the political game unfortunately.</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>That looks lovely, but what’s the mutant on th...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Who will rid me of these meddlesome Golden Kni...</td>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>We were all duped? I’ve seen through her from ...</td>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>\"Lol, hold my craft beer.\"</td>\n",
              "      <td>[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b0436d0-6c75-4d0e-86f6-becd651bc31a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b0436d0-6c75-4d0e-86f6-becd651bc31a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b0436d0-6c75-4d0e-86f6-becd651bc31a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "introduction_file_doc = nlp(train_data['code'].values[0])\n",
        "print ([token.text for token in introduction_file_doc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbYwTKfK69bY",
        "outputId": "c831802b-f453-43fa-d3c6-e35ec4c22cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['            ', 'var', 'result', '=', 'testObj1', '|', 'testObj2', ';', '\\n\\n             ', '//', 'Assert', '\\n\\n             ', 'Assert', '.', 'AreEqual(expected', ',', 'result', '.', 'ToString', '(', ')', ')', ';', '\\n\\n         ', '}', '\\n\\n         ', '[', 'TestCase(1', ',', '1', ',', '1', ',', '1', ',', '\"', '1', '\"', ')', ']', '\\n\\n         ', '[', 'TestCase(5', ',', '3', ',', '8', ',', '4', ',', '\"', '0000', '\"', ')', ']', '\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssAtpuww0p9t"
      },
      "source": [
        "## Creating our Templete\n",
        "\n",
        "So, with this `train_model` we are going to text the various differetn techniques and pare to see which works best!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pak9Mmym0rrg"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost\n",
        "from sklearn.svm import LinearSVC\n",
        "def train_model(X, y):\n",
        "\n",
        "  # Splitting the dataset into training and testing,  also by using stratify, we are making sure to use the same class balance between training and testing. \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=0)\n",
        "\n",
        "  clf=xgboost.XGBClassifier(learning_rate=0.001,n_estimators=100,reg_alpha=0.03)\n",
        "  #clf=LGBMClassifier(num_leaves=60,min_child_samples=5,max_depth=-1,learning_rate=0.1,reg_alpha=0.03)\n",
        "  \n",
        "  #clf=SGDClassifier(penalty='l2',learning_rate='adaptive',eta0=0.01)\n",
        "  # Creating and training sklearn's Decision Tree Classifier Model \n",
        "  # clf = LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,  \n",
        "  #                  intercept_scaling=1, l1_ratio=None, max_iter=200,  \n",
        "  #                  multi_class='multinomial', n_jobs=-1, penalty='l2',  \n",
        "  #                  random_state=0, solver='lbfgs', tol=0.0001, verbose=0,  \n",
        "  #                  warm_start=False)\n",
        "  clf.fit(X_train, y_train)\n",
        "\n",
        "  # Getting the predictions form unseen (testing dataset)\n",
        "  predictions = clf.predict(X_test)\n",
        "\n",
        "  # Calcuating the metrics \n",
        "  f1 = f1_score(y_test, predictions, average='weighted')\n",
        "  accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "  # Creating the table\n",
        "  console = Console()\n",
        "  result_table = Table(show_header=False, header_style=\"bold magenta\")\n",
        "\n",
        "  result_table.add_row(\"F1 Score\", str(f1))\n",
        "  result_table.add_row(\"Accuracy Score\", str(accuracy))\n",
        "\n",
        "  # Showing the table\n",
        "  console.print(result_table)\n",
        "\n",
        "  return f1, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epQQxuvY5jsL"
      },
      "source": [
        "## Simple Tokenization 🪙\n",
        "\n",
        "Here, all what we are doing is splitting the senteces into tokens/words, and then assigning a unique id to each token, and here we go, we converted the text into a vector. We are also using padding to make sure all vectors are of `maxlen` which is 256. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcKoRm1O29sq"
      },
      "source": [
        "def tokenize_sentence(sentences, num_words=10000, maxlen=256, show=False): \n",
        "\n",
        "  # Creating the tokenizer, the num_words represents the vocabulary and assigning OOV token ( out of vocaculary ) for unknown tokenn\n",
        "  # Which can arise if we input a sentence containing a words that tokenizer don't have in his vocabulary\n",
        "\n",
        "  tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "\n",
        "\n",
        "  tokenizer.fit_on_texts(sentences)\n",
        "  \n",
        "  # Getting the unique ID for each token\n",
        "  word_index = tokenizer.word_index\n",
        "\n",
        "  # Convert the senteces into vector\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "  # Padding the vectors so that all vectors have the same length\n",
        "  padded_sequences = pad_sequences(sequences, padding='post', truncating='pre', maxlen=maxlen)\n",
        "\n",
        "\n",
        "  word_index = np.asarray(word_index)\n",
        "  sequences = np.asarray(sequences)\n",
        "  padded_sequences = np.asarray(padded_sequences)\n",
        "\n",
        "  if show==True:\n",
        "    console = Console()\n",
        "\n",
        "    console.log(\"Word Index. A unique ID is assigned to each token.\")\n",
        "    console.log(word_index)\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "    console.log(\"Sequences. senteces converted into vector.\")\n",
        "    console.log(np.array(sequences[0]))\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "    console.log(\"Padded Sequences. Adding,( 0 in this case ) or removing elements to make all vectors in the samples same.\")\n",
        "    console.log(np.array(padded_sequences[0]))\n",
        "    console.log(\"---\"*10)\n",
        "\n",
        "\n",
        "\n",
        "  return tokenizer, word_index, sequences, padded_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPE3U58jN1xh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "dc9661dd-5b27-45b2-e356-9f26ab45cf9d"
      },
      "source": [
        "# Sample Senteces\n",
        "sample_sentences = dataset.iloc[0, 1].split(\".\")\n",
        "sample_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">[</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">\"Incels can't even get a pleb thing called sex\"</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">' Sex is for [NAME] apparently'</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">''</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m[\u001b[0m\n",
              "    \u001b[32m\"Incels can't even get a pleb thing called sex\"\u001b[0m,\n",
              "    \u001b[32m' Sex is for \u001b[0m\u001b[32m[\u001b[0m\u001b[32mNAME\u001b[0m\u001b[32m]\u001b[0m\u001b[32m apparently'\u001b[0m,\n",
              "    \u001b[32m''\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ZpPcbi8HvT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "outputId": "d971c980-a260-4cf2-a49d-f48b9aebd790"
      },
      "source": [
        "_, _, _, _ = tokenize_sentence(sample_sentences, num_words=50, maxlen=16, show=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[10:20:41] </span>Word Index. A unique ID is assigned to each     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:28</span>\n",
              "           token.                                                                            \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[10:20:41]\u001b[0m\u001b[2;36m \u001b[0mWord Index. A unique ID is assigned to each     \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m28\u001b[0m\n",
              "           token.                                                                            \n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;OOV&gt;'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sex'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'incels'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"can't\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:29</span>\n",
              "           <span style=\"color: #008000; text-decoration-color: #008000\">'even'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'get'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pleb'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,                                           \n",
              "           <span style=\"color: #008000; text-decoration-color: #008000\">'thing'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'called'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'is'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'for'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,                                    \n",
              "           <span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'apparently'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"font-weight: bold\">}</span>                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mOOV\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'sex'\u001b[0m: \u001b[1;36m2\u001b[0m, \u001b[32m'incels'\u001b[0m: \u001b[1;36m3\u001b[0m, \u001b[32m\"can't\"\u001b[0m: \u001b[1;36m4\u001b[0m, \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m29\u001b[0m\n",
              "           \u001b[32m'even'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'get'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'a'\u001b[0m: \u001b[1;36m7\u001b[0m, \u001b[32m'pleb'\u001b[0m: \u001b[1;36m8\u001b[0m,                                           \n",
              "           \u001b[32m'thing'\u001b[0m: \u001b[1;36m9\u001b[0m, \u001b[32m'called'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'is'\u001b[0m: \u001b[1;36m11\u001b[0m, \u001b[32m'for'\u001b[0m: \u001b[1;36m12\u001b[0m,                                    \n",
              "           \u001b[32m'name'\u001b[0m: \u001b[1;36m13\u001b[0m, \u001b[32m'apparently'\u001b[0m: \u001b[1;36m14\u001b[0m\u001b[1m}\u001b[0m                                                     \n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>------------------------------                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:30</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m------------------------------                  \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m30\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Sequences. senteces converted into vector.      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:32</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSequences. senteces converted into vector.      \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m32\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span>                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:33</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m3\u001b[0m  \u001b[1;36m4\u001b[0m  \u001b[1;36m5\u001b[0m  \u001b[1;36m6\u001b[0m  \u001b[1;36m7\u001b[0m  \u001b[1;36m8\u001b[0m  \u001b[1;36m9\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m                    \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m33\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>------------------------------                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:34</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m------------------------------                  \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m34\u001b[0m\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Padded Sequences. Adding,<span style=\"font-weight: bold\">(</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> in this case <span style=\"font-weight: bold\">)</span> or  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:36</span>\n",
              "           removing elements to make all vectors in the                                      \n",
              "           samples same.                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mPadded Sequences. Adding,\u001b[1m(\u001b[0m \u001b[1;36m0\u001b[0m in this case \u001b[1m)\u001b[0m or  \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m36\u001b[0m\n",
              "           removing elements to make all vectors in the                                      \n",
              "           samples same.                                                                     \n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:37</span>\n",
              "           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>                                                                                \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m3\u001b[0m  \u001b[1;36m4\u001b[0m  \u001b[1;36m5\u001b[0m  \u001b[1;36m6\u001b[0m  \u001b[1;36m7\u001b[0m  \u001b[1;36m8\u001b[0m  \u001b[1;36m9\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;36m2\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m  \u001b[1;36m0\u001b[0m   \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m37\u001b[0m\n",
              "           \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m                                                                                \n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>------------------------------                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">&lt;ipython-input-13-034b9db2f918&gt;:38</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m------------------------------                  \u001b[2m<ipython-input-13-034b9db2f918>\u001b[0m\u001b[2m:\u001b[0m\u001b[2m38\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVgOHdM0pYmU"
      },
      "source": [
        "# Training the model using the vectors and the features\n",
        "\n",
        "tokenizer, _, _, X = tokenize_sentence(train_data['code'].values)\n",
        "y = train_data['language'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJxozn9WwPvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d602a61-1acd-4c09-da31-532e26633be6"
      },
      "source": [
        "print(\"Sentence : \", train_data['code'][2])\n",
        "print(\"Simple Tokenizer : \", X[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :  /*\n",
            "\n",
            "     Explanation :- a user gives a String (it can be incomplete uppercase or\n",
            "\n",
            "         partial uppercase) and then the program would convert it into a\n",
            "\n",
            "         complete(all characters in lower case) lower case string. The\n",
            "\n",
            "Simple Tokenizer :  [ 862    8  377 1465    8   33   90  179   49    1 1531  109 3361 1531\n",
            "   24  247    3  467  821  442   90  295    8 1489  123  450   15  372\n",
            "  156  372  156   33    3    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLXlja-23yy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "34744947-76dd-4081-c959-1b43a64d458e"
      },
      "source": [
        "token_id_f1, token_id_accuracy = train_model(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.2680233576431608 ┃\n",
              "│ Accuracy Score │ 0.3449484987946526 │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.2680233576431608 ┃\n",
              "│ Accuracy Score │ 0.3449484987946526 │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer, _, _, _ = tokenize_sentence(train_data['code'].values, num_words=256)\n",
        "X = tokenizer.texts_to_matrix(train_data['code'].values,mode='freq')"
      ],
      "metadata": {
        "id": "BYclNCW-fVj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_f1,_accuracy = train_model(X, y)"
      ],
      "metadata": {
        "id": "n1UpBIMMfVnf",
        "outputId": "bc103b3a-be46-4523-9c77-9a903937c11c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5278126775704207 ┃\n",
              "│ Accuracy Score │ 0.544488275257506  │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5278126775704207 ┃\n",
              "│ Accuracy Score │ 0.544488275257506  │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer, _, _, _ = tokenize_sentence(train_data['code'].values, num_words=256)\n",
        "X = tokenizer.texts_to_matrix(train_data['code'].values,mode='binary')"
      ],
      "metadata": {
        "id": "fNVbcoEWgRWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_f1,_accuracy = train_model(X, y)"
      ],
      "metadata": {
        "id": "PfSIR5_ygReC",
        "outputId": "eb2f59ed-bc00-4c55-b9c8-cf9514053c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5237139721267318 ┃\n",
              "│ Accuracy Score │ 0.5408722331799255 │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5237139721267318 ┃\n",
              "│ Accuracy Score │ 0.5408722331799255 │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBWO5JYB7Hei"
      },
      "source": [
        "Now, the advantages of this method is that it is very simple, but one of the major disadvantages for this is it doesn't contain the \"meaning\" of the text, and mny next will also not be able to solve this issue, unzip word2vec  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W449h9w1N0MF"
      },
      "source": [
        "## Bag of Words 🎒\n",
        "\n",
        "In Bag of Words, instead of what we did in simple tokenization, just assiging a unique ID to each token, bag of words, does things a little different.\n",
        "\n",
        "I find bag of words harder to understand with a text, so i find [this](https://youtu.be/UFtXy0KRxVI) video really helpful for understand bag of words in a more visual way. Be sure to watch it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zebC0aB5ocP"
      },
      "source": [
        "tokenizer, _, _, _ = tokenize_sentence(train_data['code'].values, num_words=256)\n",
        "X = tokenizer.texts_to_matrix(train_data['code'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d47BtTyNvnI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65113a5d-8857-429b-ffcf-53c95e0474bd"
      },
      "source": [
        "print(\"Sentence : \", train_data['code'][0])\n",
        "print(\"BOW : \", X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :              var result = testObj1 | testObj2;\n",
            "\n",
            "             // Assert\n",
            "\n",
            "             Assert.AreEqual(expected, result.ToString());\n",
            "\n",
            "         }\n",
            "\n",
            "         [TestCase(1, 1, 1, 1, \"1\")]\n",
            "\n",
            "         [TestCase(5, 3, 8, 4, \"0000\")]\n",
            "\n",
            "BOW :  [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wucSGLbf-Euk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "832d12f6-4596-4f6f-c619-2514417eb3ce"
      },
      "source": [
        "bow_f1, bow_accuracy = train_model(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5237139721267318 ┃\n",
              "│ Accuracy Score │ 0.5408722331799255 │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5237139721267318 ┃\n",
              "│ Accuracy Score │ 0.5408722331799255 │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jsWqu7dt-Vo"
      },
      "source": [
        "Yee! both of the metrics did increased! Advantages of Bag of words is that it's again, really simple, but it doesn't keep the same order of words in sentence and doesn't keep the meaning of the sentence.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_ooq4qQBBix"
      },
      "source": [
        "## Count Vectorization 🔢\n",
        "\n",
        "Count Vectorization is also very similar to Bag of Wards but instead of one hot, it also include the count of each token in a sentece. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6MOYJmLBD5U"
      },
      "source": [
        "tokenizer, _, x, xx = tokenize_sentence(train_data['code'].values, num_words=256)\n",
        "X = tokenizer.texts_to_matrix(train_data['code'].values, mode='count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qSGe0xRwRJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c29ab26-3be5-4432-bd9e-523288d14ea8"
      },
      "source": [
        "print(\"Sentence : \", train_data['code'][2])\n",
        "print(\"CV : \", X[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :  /*\n",
            "\n",
            "     Explanation :- a user gives a String (it can be incomplete uppercase or\n",
            "\n",
            "         partial uppercase) and then the program would convert it into a\n",
            "\n",
            "         complete(all characters in lower case) lower case string. The\n",
            "\n",
            "CV :  [ 0. 15.  0.  2.  0.  0.  0.  0.  3.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THXwnIMcBMIw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "57b703d7-8f6b-487b-995d-a2320892f4f8"
      },
      "source": [
        "count_f1, count_accuracy = train_model(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5273012040061048 ┃\n",
              "│ Accuracy Score │ 0.5430637738330046 │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5273012040061048 ┃\n",
              "│ Accuracy Score │ 0.5430637738330046 │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_f1, count_accuracy = train_model(xx, y)"
      ],
      "metadata": {
        "id": "4Zj9LlmggzuH",
        "outputId": "5404d8bd-8e46-42d4-c66b-758701b08167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.3086611316667192  ┃\n",
              "│ Accuracy Score │ 0.37409598948060485 │\n",
              "└────────────────┴─────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.3086611316667192  ┃\n",
              "│ Accuracy Score │ 0.37409598948060485 │\n",
              "└────────────────┴─────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMJ0iml5N2KE"
      },
      "source": [
        "## TF - IDF 📐\n",
        "\n",
        "TF-IDF is **Term Frequency - Inverse Document Frequency**. So as we way in last section, about count frequency, that had a bit of flaw, for ex. tokens such a `is, are, the` are very common and will generally have bigger counts, but they don't ususally help for ex. classify whether the text is positive or negative. TF-IDF actually try to solve this issue. TF-IDF applies lower score to the common tokens and higher scores for more rarer tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYqjZTJ3N4AZ"
      },
      "source": [
        "tokenizer, _, _, x = tokenize_sentence(train_data['code'].values, num_words=256)\n",
        "X = tokenizer.texts_to_matrix(train_data['code'].values, mode='tfidf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj2LnbyrwRy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58f3a61a-25e1-4caa-a76a-7ecaec2ed5ba"
      },
      "source": [
        "print(\"Sentence : \", train_data['code'][0])\n",
        "print(\"TF-IDF : \", X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence :              var result = testObj1 | testObj2;\n",
            "\n",
            "             // Assert\n",
            "\n",
            "             Assert.AreEqual(expected, result.ToString());\n",
            "\n",
            "         }\n",
            "\n",
            "         [TestCase(1, 1, 1, 1, \"1\")]\n",
            "\n",
            "         [TestCase(5, 3, 8, 4, \"0000\")]\n",
            "\n",
            "TF-IDF :  [ 0.         31.60460419  4.23447758  0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          2.57234506  0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          2.88231493  2.92883682\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          5.82824057  0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          3.58251801  0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  6.31346134  0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          3.694688    0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          4.48009244\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql-pxhL4BRQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "6f356d03-50e5-4cde-f1a3-6f2614d06a2c"
      },
      "source": [
        "tfidf_f1, tfidf_accuracy = train_model(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5273012040061048 ┃\n",
              "│ Accuracy Score │ 0.5430637738330046 │\n",
              "└────────────────┴────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.5273012040061048 ┃\n",
              "│ Accuracy Score │ 0.5430637738330046 │\n",
              "└────────────────┴────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_f1, tfidf_accuracy = train_model(x, y)"
      ],
      "metadata": {
        "id": "LwKmIbadhTi1",
        "outputId": "0aaa1194-0cd4-4667-e439-c050e35a1fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.3086611316667192  ┃\n",
              "│ Accuracy Score │ 0.37409598948060485 │\n",
              "└────────────────┴─────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃ F1 Score       ┃ 0.3086611316667192  ┃\n",
              "│ Accuracy Score │ 0.37409598948060485 │\n",
              "└────────────────┴─────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEX46cGwZyuI"
      },
      "source": [
        "# Prediction phase 🔎\n",
        "\n",
        "Generating the features in test dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocahSMTyNkg9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "2cf9bcfe-ddd9-4675-eddd-ceb0611e708d"
      },
      "source": [
        "test_dataset = pd.read_csv(AICROWD_DATASET_PATH)\n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a71c6ed3-237a-4220-988f-34c6464e371b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Incels can't even get a pleb thing called sex....</td>\n",
              "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Seriously? I couldn't even remember the dude's...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Seeing [NAME] on Sunday and I'm so fucking stoked</td>\n",
              "      <td>[0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Your not winning their hearts, your just tortu...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This sub needs more Poison memes.</td>\n",
              "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>It is part of the political game unfortunately.</td>\n",
              "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>That looks lovely, but what’s the mutant on th...</td>\n",
              "      <td>[0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Who will rid me of these meddlesome Golden Kni...</td>\n",
              "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>We were all duped? I’ve seen through her from ...</td>\n",
              "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>\"Lol, hold my craft beer.\"</td>\n",
              "      <td>[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a71c6ed3-237a-4220-988f-34c6464e371b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a71c6ed3-237a-4220-988f-34c6464e371b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a71c6ed3-237a-4220-988f-34c6464e371b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english',max_features=256)\n",
        "X = vectorizer.fit_transform(train_data['code'].values)"
      ],
      "metadata": {
        "id": "apuQoTB0vxvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.cluster import KMeans\n",
        "# true_k = 10\n",
        "# model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
        "# model.fit(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0CfsSUwvMyQ",
        "outputId": "983efb41-78d2-467a-fdf1-9ac953671194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(max_iter=100, n_clusters=10, n_init=1)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "# terms = vectorizer.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxAMR5os3hMy",
        "outputId": "25cf4de6-17c4-461d-883b-fd4bbbe3aeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "id": "dclnR28w3i2H",
        "outputId": "5d7dbbd7-bd74-42e3-bf13-3160e7326f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m(\u001b[0m\u001b[1;36m10\u001b[0m, \u001b[1;36m256\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(true_k):\n",
        "#  print('Cluster %d:' % i),\n",
        "#  for ind in order_centroids[i, :10]:\n",
        "#    print(' %s' % terms[ind])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeLlVxq44osf",
        "outputId": "92ac750a-ba92-4a68-cccd-987a246dd562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0:\n",
            " node\n",
            " right\n",
            " left\n",
            " root\n",
            " null\n",
            " return\n",
            " parent\n",
            " data\n",
            " value\n",
            " key\n",
            "Cluster 1:\n",
            " return\n",
            " number\n",
            " array\n",
            " true\n",
            " param\n",
            " list\n",
            " print\n",
            " value\n",
            " 10\n",
            " false\n",
            "Cluster 2:\n",
            " 20\n",
            " 10\n",
            " 15\n",
            " 30\n",
            " include\n",
            " 17\n",
            " 12\n",
            " test\n",
            " 11\n",
            " 50\n",
            "Cluster 3:\n",
            " int\n",
            " return\n",
            " list\n",
            " def\n",
            " void\n",
            " array\n",
            " arr\n",
            " number\n",
            " new\n",
            " size\n",
            "Cluster 4:\n",
            " public\n",
            " class\n",
            " void\n",
            " static\n",
            " test\n",
            " new\n",
            " int\n",
            " summary\n",
            " private\n",
            " namespace\n",
            "Cluster 5:\n",
            " std\n",
            " cout\n",
            " endl\n",
            " vector\n",
            " int\n",
            " test\n",
            " double\n",
            " passed\n",
            " assert\n",
            " cin\n",
            "Cluster 6:\n",
            " self\n",
            " def\n",
            " return\n",
            " node\n",
            " index\n",
            " data\n",
            " len\n",
            " str\n",
            " range\n",
            " list\n",
            "Cluster 7:\n",
            " main\n",
            " printf\n",
            " int\n",
            " function\n",
            " return\n",
            " exit\n",
            " void\n",
            " test\n",
            " brief\n",
            " returns\n",
            "Cluster 8:\n",
            " string\n",
            " return\n",
            " str\n",
            " text\n",
            " length\n",
            " int\n",
            " param\n",
            " new\n",
            " std\n",
            " input\n",
            "Cluster 9:\n",
            " __main__\n",
            " __name__\n",
            " doctest\n",
            " testmod\n",
            " print\n",
            " import\n",
            " return\n",
            " solution\n",
            " main\n",
            " input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in test_dataset['text'].values:\n",
        "#   print(i)\n",
        "#   X = vectorizer.transform([i])\n",
        "#   predicted = model.predict(X)\n",
        "#   print(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht84lv4fvM1l",
        "outputId": "2795c5b2-ada8-41a1-ba08-510f57d42160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incels can't even get a pleb thing called sex. Sex is for [NAME] apparently.\n",
            "[1]\n",
            "Seriously? I couldn't even remember the dude's name until about halfway through the season honestly.\n",
            "[1]\n",
            "Seeing [NAME] on Sunday and I'm so fucking stoked\n",
            "[1]\n",
            "Your not winning their hearts, your just torturing them and they end up hating you.\n",
            "[1]\n",
            "This sub needs more Poison memes.\n",
            "[1]\n",
            "It is part of the political game unfortunately.\n",
            "[1]\n",
            "That looks lovely, but what’s the mutant on the top?\n",
            "[1]\n",
            "Who will rid me of these meddlesome Golden Knights?\n",
            "[1]\n",
            "We were all duped? I’ve seen through her from day 1, even posted about how fake she is\n",
            "[1]\n",
            "\"Lol, hold my craft beer.\"\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# len(vectorizer.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "CZ1JKK7k3NNs",
        "outputId": "122a5881-2f99-4e2c-dcc9-576c2cc786a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m256\u001b[0m\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNAkGqKBv-go",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395,
          "referenced_widgets": [
            "47009e862f264ac5b46ae009c1ee4183",
            "acdad89e82274720ab1ed63433a287b9",
            "3d6a12ed86a744ee985153e48731494c",
            "d828d97871704b6cbb5d71d164d1de4b",
            "045501585ff347b7a32152905f582e01",
            "7152b80401e348068a4e8a619008e746",
            "dd6825f3728d4e7bbd3d71eb81597284",
            "83f289d1aed0412cba5642ae970bcf47",
            "2e17f6029d9e49898eec89beea0f8994",
            "4ca27a545b174ba2aac3d63684cc9fc9",
            "17952e2d36c24ebca462867927b12c59"
          ]
        },
        "outputId": "5f0646b6-bf48-4175-91b6-491fed721695"
      },
      "source": [
        "# So, let's do a simple tokenization and generate the features!\n",
        "# tokenizer, _, _, _ = tokenize_sentence(test_dataset['text'].values, num_words=256)\n",
        "# #tokenizer.texts_to_matrix()\n",
        "# X = tokenizer.texts_to_matrix(test_dataset['text'].values, mode='tfidf')\n",
        "\n",
        "X=vectorizer.transform(test_dataset['text'].values)\n",
        "X=X.toarray()\n",
        "\n",
        "#_, _, _, X = tokenize_sentence(test_dataset['text'].values)\n",
        "\n",
        "for index, row in tqdm(test_dataset.iterrows()):\n",
        "  test_dataset.iloc[index, 2] = str(X[index])\n",
        "\n",
        "# for index, row in tqdm(test_dataset.iterrows()):\n",
        "#   test_dataset.iloc[index, 2] = str(X[index].tolist())\n",
        "\n",
        "test_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47009e862f264ac5b46ae009c1ee4183",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4401e0b6-e18b-4008-b038-0f7fcf16f9a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Incels can't even get a pleb thing called sex....</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Seriously? I couldn't even remember the dude's...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Seeing [NAME] on Sunday and I'm so fucking stoked</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Your not winning their hearts, your just tortu...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>This sub needs more Poison memes.</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>It is part of the political game unfortunately.</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>That looks lovely, but what’s the mutant on th...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Who will rid me of these meddlesome Golden Kni...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>We were all duped? I’ve seen through her from ...</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>\"Lol, hold my craft beer.\"</td>\n",
              "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4401e0b6-e18b-4008-b038-0f7fcf16f9a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4401e0b6-e18b-4008-b038-0f7fcf16f9a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4401e0b6-e18b-4008-b038-0f7fcf16f9a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R07_U_YFwC9C"
      },
      "source": [
        "# Saving the sample submission\n",
        "test_dataset.to_csv(os.path.join(AICROWD_OUTPUTS_PATH,'submission.csv'), index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx6nuUzrwnC6"
      },
      "source": [
        "# Submit to AIcrowd 🚀\n",
        "\n",
        "**Note : Please save the notebook before submitting it (Ctrl + S)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X95c_97SwqP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360,
          "referenced_widgets": [
            "42531cf0d4ce4666a5571945112a6473",
            "bc8500232b84467c81f5fdce275825c3"
          ]
        },
        "outputId": "fc852498-3eb1-4d53-9254-8a80b511cd36"
      },
      "source": [
        "%aicrowd notebook submit --assets-dir $AICROWD_ASSETS_DIR --challenge nlp-feature-engineering-2 --no-verify"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: No assets directory at assets... Creating one...\n",
            "WARNING: Assets directory is empty\n",
            "Using notebook: NLP Feature Engineering #2 Baseline for submission...\n",
            "Scrubbing API keys from the notebook...\n",
            "Collecting notebook...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42531cf0d4ce4666a5571945112a6473",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                                       ╭─────────────────────────╮                                                       \n",
              "                                                       │ <span style=\"font-weight: bold\">Successfully submitted!</span> │                                                       \n",
              "                                                       ╰─────────────────────────╯                                                       \n",
              "</pre>\n"
            ],
            "text/plain": [
              "                                                       ╭─────────────────────────╮                                                       \n",
              "                                                       │ \u001b[1mSuccessfully submitted!\u001b[0m │                                                       \n",
              "                                                       ╰─────────────────────────╯                                                       \n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                             Important links                                                             </span>\n",
              "┌──────────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│  This submission │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/submissions/170715              │\n",
              "│                  │                                                                                                                    │\n",
              "│  All submissions │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/submissions?my_submissions=true │\n",
              "│                  │                                                                                                                    │\n",
              "│      Leaderboard │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/leaderboards                    │\n",
              "│                  │                                                                                                                    │\n",
              "│ Discussion forum │ https://discourse.aicrowd.com/c/ai-blitz-xii                                                                       │\n",
              "│                  │                                                                                                                    │\n",
              "│   Challenge page │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2                                 │\n",
              "└──────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                                                             Important links                                                             \u001b[0m\n",
              "┌──────────────────┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
              "│  This submission │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/submissions/170715              │\n",
              "│                  │                                                                                                                    │\n",
              "│  All submissions │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/submissions?my_submissions=true │\n",
              "│                  │                                                                                                                    │\n",
              "│      Leaderboard │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2/leaderboards                    │\n",
              "│                  │                                                                                                                    │\n",
              "│ Discussion forum │ https://discourse.aicrowd.com/c/ai-blitz-xii                                                                       │\n",
              "│                  │                                                                                                                    │\n",
              "│   Challenge page │ https://www.aicrowd.com/challenges/ai-blitz-xii/problems/nlp-feature-engineering-2                                 │\n",
              "└──────────────────┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}